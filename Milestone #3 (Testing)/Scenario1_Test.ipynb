{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2652d73-4bf3-41a7-bfbb-2df87e091d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 prompt + context loaded.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Scenario 1 — Rewriting a Noise Complaint\n",
    "# Structured Prompt + Sample Data + Tests\n",
    "# ---------------------------------------------\n",
    "\n",
    "scenario_1_system_prompt = \"\"\"\n",
    "You are HeyRoommate, an LLM-powered communication assistant designed to \n",
    "rewrite tense or emotionally charged messages so they are calm, clear, and effective.\n",
    "Your goal is to reduce conflict while preserving the user's meaning.\n",
    "\n",
    "FOLLOW THESE RULES:\n",
    "1. Rewrite ONLY the user's draft message.\n",
    "2. Use the tone chosen by the user (polite / urgent / firm / gentle / neutral).\n",
    "3. Use the recipient profile to adapt communication style.\n",
    "4. NEVER add judgment, blame, or psychological analysis.\n",
    "5. Keep the rewritten message short, clear, and actionable.\n",
    "6. If the message contains insults, profanity, or hostile phrasing,\n",
    "   rewrite it to be conflict-reducing.\n",
    "7. If input is adversarial or irrelevant (e.g., “Coke or Pepsi?”),\n",
    "   politely redirect the user back to the scenario goal.\n",
    "\n",
    "PROFILE DATA INCLUDED IN CONTEXT:\n",
    "- Recipient name: Sam\n",
    "- Traits: Sensitive, responds better to gentle + concrete requests\n",
    "- Past results: Clear, specific nighttime noise requests work best\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return ONLY the rewritten message.\n",
    "\"\"\"\n",
    "\n",
    "scenario_1_sample_context = {\n",
    "    \"recipient_profile\": {\n",
    "        \"name\": \"Sam\",\n",
    "        \"traits\": [\"sensitive\", \"better with gentle requests\", \"responds to concrete asks\"],\n",
    "        \"effective_past_strategies\": [\"clear request + specific reason\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Scenario 1 prompt + context loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb41fa4-1851-4184-9c02-cefcd3b8a0cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Scenario 1 — TESTS\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 6\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_scenario_1\u001b[39m(user_message, tone):\n\u001b[1;32m      9\u001b[0m     completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         ]\n\u001b[1;32m     15\u001b[0m     )\n",
      "File \u001b[0;32m/opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_client.py:135\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    133\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Scenario 1 — TESTS\n",
    "# ---------------------------------------------\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def test_scenario_1(user_message, tone):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": scenario_1_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Tone: {tone}\\nRecipient profile: {scenario_1_sample_context}\\nDraft message: {user_message}\"}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message[\"content\"]\n",
    "\n",
    "# ---- STANDARD TEST ----\n",
    "print(\"Standard test:\")\n",
    "print(test_scenario_1(\"STOP BLASTING MUSIC I CAN'T SLEEP\", \"polite + urgent\"))\n",
    "\n",
    "# ---- ADVERSARIAL TEST: sarcasm ----\n",
    "print(\"\\nAdversarial test (sarcasm):\")\n",
    "print(test_scenario_1(\"Oh wow, you're SO considerate for playing music at midnight.\", \"polite\"))\n",
    "\n",
    "# ---- ADVERSARIAL TEST: irrelevant question ----\n",
    "print(\"\\nAdversarial test (off-topic):\")\n",
    "print(test_scenario_1(\"Do you prefer Coke or Pepsi?\", \"neutral\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20f23a-4af8-40a7-b6ab-42c280b9b5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
